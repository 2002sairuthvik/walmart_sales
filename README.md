# ğŸ›ï¸ Walmart Sales Data Analysis and Dashboard

This project demonstrates a complete data analysis pipeline using a Walmart sales dataset. The process includes data cleaning and transformation in Python, performing business-level analysis using SQL, and building an interactive dashboard in Power BI.

---

## ğŸ“ Project Structure
<pre> ``` WALMART_SALES/ â”œâ”€â”€ my_venv_walmart/ # Python virtual environment â”‚ â”œâ”€â”€ Include/ â”‚ â”œâ”€â”€ Lib/ â”‚ â”œâ”€â”€ Scripts/ â”‚ â””â”€â”€ pyvenv.cfg â”œâ”€â”€ Data_cleaning.ipynb # Jupyter notebook for data preprocessing â”œâ”€â”€ requirements.txt # Python dependencies â”œâ”€â”€ sql_queries.sql # Business analysis SQL queries â”œâ”€â”€ Walmart_cleaned.csv # Cleaned dataset ready for SQL/BI â”œâ”€â”€ walmart_sales_visualisation.pbix # Power BI dashboard â”œâ”€â”€ walmart-10k-sales-datasets.zip # Original dataset (zipped) â””â”€â”€ Walmart.csv # Raw dataset (extracted) ``` </pre>

## ğŸ§° Technologies Used

- **Python** â€“ Data cleaning & preprocessing
- **MySQL** â€“ Data analysis with SQL
- **Power BI** â€“ Data visualization and dashboard creation
- **VS Code** â€“ Development environment with Jupyter extension
- **Libraries Used:**
  - `pandas` â€“ for data manipulation
  - `numpy` â€“ for numerical operations
  - `sqlalchemy` â€“ for SQL connection/ORM
  - `pymysql` â€“ to connect Python with MySQL

## ğŸ“Š Dataset Info

- **Source**: [Kaggle - Walmart 10K Sales Dataset](https://www.kaggle.com/datasets/najir0123/walmart-10k-sales-datasets)
- **Rows**: 10,000  
- **Columns**:
  - `invoice_id` â€“ Unique identifier for each transaction
  - `Branch` â€“ Store branch (A, B, or C)
  - `City` â€“ City where the store is located
  - `Category` â€“ Product category sold
  - `unit_price` â€“ Price per unit of the item
  - `quantity` â€“ Quantity of items sold
  - `date` â€“ Date of transaction
  - `time` â€“ Time of transaction
  - `payment_method` â€“ Type of payment used
  - `rating` â€“ Customer rating (1â€“10 scale)
  - `profit_margin` â€“ Profit earned on transaction

## ğŸ”§ Step-by-Step Workflow

### âœ… Step 1: Data Collection
- Downloaded the dataset from Kaggle.
- Extracted the raw dataset as `Walmart.csv`.

### ğŸ§¹ Step 2: Data Cleaning & Feature Engineering (Python)
- Environment setup with Jupyter in VS Code.
- Created a virtual environment and added a `requirements.txt` with all dependencies.
- Used `pandas` and `numpy` for data preprocessing:
  - Checked for null values â€” filled `unit_price` and `quantity` with mean values.
  - Removed duplicates.
  - Fixed incorrect data types.
  - Added a new column `Total_Amount = unit_price * quantity`.
- Exported the cleaned data to `Walmart_cleaned.csv`.

### ğŸ›¢ï¸ Step 3: Data Analysis (MySQL)
- Created a database in MySQL.
- Connected Python to MySQL using SQLAlchemy and PyMySQL.
- Loaded the cleaned data into MySQL.
- Wrote SQL queries to analyze business problems such as:
  - Most used payment methods
  - Highest-rated categories per branch
  - Busiest sales days
  - Average, min, max ratings by city/category
  - Sales categorized by shift (Morning, Afternoon, Evening)
  - Branches with the highest revenue drop year over year

### ğŸ“Š Step 4: Data Visualization (Power BI)
- Connected Power BI to MySQL database using credentials.
- Imported results from SQL queries to visualize:
  - Sales trends by category, day, branch
  - Rating and revenue comparisons
  - Preferred payment methods
  - Year-wise revenue differences
- Created an interactive dashboard (`walmart_sales_visualisation.pbix`)
  
## ğŸš€ Getting Started

Follow these steps to set up and run the project on your local machine:



